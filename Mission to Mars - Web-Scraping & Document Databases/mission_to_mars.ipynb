{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from splinter import Browser\n",
    "from splinter.exceptions import ElementDoesNotExist\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML, Image, display\n",
    "from mission_to_mars import scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create beautiful soup object from html, create a function\n",
    "def scrape(url):\n",
    "    executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "    browser = Browser('chrome', **executable_path, headless=False)\n",
    "    browser.visit(url)\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NASA Mars News\n",
    "\n",
    "* Scrape the [NASA Mars News Site](https://mars.nasa.gov/news/) and collect the latest News Title and Paragraph Text. Assign the text to variables that you can reference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save URL, use scrape function created and save as variable name\n",
    "url_news = \"https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest\"\n",
    "soup = scrape(url_news)\n",
    "\n",
    "# Collect latest news title & paragraph text\n",
    "latest_news = soup.find(\"ul\", class_=\"item_list\").find(\"div\",class_ = \"content_title\").a.text\n",
    "latest_paragraph = soup.find(\"ul\", class_=\"item_list\").find(\"div\",class_ = \"article_teaser_body\").text\n",
    "\n",
    "print(f'''\n",
    "The most recent article is: \"{latest_news}\"\n",
    "The most recent paragraph is: \"{latest_paragraph}\"\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JPL Mars Space Images - Featured Image\n",
    "\n",
    "* Visit the url for JPL Featured Space Image [here](https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars).\n",
    "\n",
    "* Use splinter to navigate the site and find the image url for the current Featured Mars Image and assign the url string to a variable called `featured_image_url`.\n",
    "\n",
    "* Make sure to find the image url to the full size `.jpg` image.\n",
    "\n",
    "* Make sure to save a complete url string for this image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save urls as variables\n",
    "url_base = \"https://www.jpl.nasa.gov\"\n",
    "url_featured = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "\n",
    "# Use function created to scrape site and find targets of scraped object\n",
    "image_soup = scrape(url_featured)\n",
    "image_url = image_soup.find(\"div\", class_=\"carousel_container\").find(\"article\", class_=\"carousel_item\")\\\n",
    ".find('a')['data-fancybox-href']\n",
    "\n",
    "# Image url output is only the path after \"url\", so must append to base url\n",
    "# example: /spaceimages/images/mediumsize/PIA09113_ip.jpg\n",
    "featured_image_url = f'{url_base}{image_url}'\n",
    "print(featured_image_url)\n",
    "\n",
    "# Display image\n",
    "display(Image(url=featured_image_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Weather\n",
    "\n",
    "* Visit the Mars Weather twitter account [here](https://twitter.com/marswxreport?lang=en) and scrape the latest Mars weather tweet from the page. Save the tweet text for the weather report as a variable called `mars_weather`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save urls as variable\n",
    "url_twitter = \"https://twitter.com/marswxreport?lang=en\"\n",
    "\n",
    "# Use function created to scrape site and find targets of scraped object\n",
    "twitter_soup = scrape(url_twitter)\n",
    "\n",
    "# Display to preview soup object\n",
    "#print(twitter_soup.prettify())\n",
    "\n",
    "# Use soup object to locate the most recent tweet with the weather\n",
    "mars_weather = (twitter_soup.find(\"div\", class_=\"js-tweet-text-container\")\\\n",
    "                .find(\"p\", class_=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\").text)\n",
    "print(f'''\n",
    "The current weather on mars is:\n",
    "{mars_weather}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Facts\n",
    "\n",
    "* Visit the Mars Facts webpage [here](http://space-facts.com/mars/) and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "\n",
    "* Use Pandas to convert the data to a HTML table string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save url as variable\n",
    "fact_url = \"https://space-facts.com/mars/\"\n",
    "\n",
    "# Use function created to scrape site and find targets of scraped object\n",
    "fact_soup = scrape(fact_url)\n",
    "\n",
    "# Create table as beautiful soup object \n",
    "table = fact_soup.find(\"table\").find(\"tbody\").find_all(\"tr\")\n",
    "\n",
    "# Iterate and print elements\n",
    "for t in table:\n",
    "    cells = t.find_all(\"td\")\n",
    "    param = cells[0].get_text()\n",
    "    data = cells[1].get_text()\n",
    "    print(f'{param}{data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another option: pandas df using pd.read_html which automatically finds tables and converts to df\n",
    "mars_df = pd.read_html(fact_url)\n",
    "mars_facts_df = pd.DataFrame(mars_df[0])\n",
    "\n",
    "# Name columns and set index\n",
    "mars_facts_df.columns = ['Parameter','Data']\n",
    "mars_df_table = mars_facts_df.set_index(\"Parameter\")\n",
    "mars_df_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the pd df to HTML table and clean up. \n",
    "mars_html_table = mars_df_table.to_html(classes='marsdata')\n",
    "mars_table = mars_html_table.replace('\\n', ' ')\n",
    "\n",
    "type(mars_table) # str\n",
    "print(mars_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Hemispheres\n",
    "\n",
    "* Visit the USGS Astrogeology site [here](https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars) to obtain high resolution images for each of Mar's hemispheres.\n",
    "\n",
    "* You will need to click each of the links to the hemispheres in order to find the image url to the full resolution image.\n",
    "\n",
    "* Save both the image url string for the full resolution hemisphere image, and the Hemisphere title containing the hemisphere name. Use a Python dictionary to store the data using the keys `img_url` and `title`.\n",
    "\n",
    "* Append the dictionary with the image url string and the hemisphere title to a list. This list will contain one dictionary for each hemisphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save url as variable\n",
    "hemi_url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "\n",
    "# Use function created to scrape site and find targets of scraped object\n",
    "hemi_soup = scrape(hemi_url)\n",
    "\n",
    "# Establish base url to prefix to links\n",
    "base_url = \"https://astrogeology.usgs.gov\"\n",
    "\n",
    "# Create object from \n",
    "item = hemi_soup.find_all(\"div\", class_=\"item\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list to append urls\n",
    "hemi_dicts = []\n",
    "\n",
    "# Loop through object, find link, append to list, add base url, and grab title\n",
    "for i in item:\n",
    "    link = i.find(class_=\"description\").a[\"href\"]\n",
    "    full_url = (base_url + link)\n",
    "    scraped = scrape(full_url)\n",
    "    img_url = scraped.find(\"div\", class_=\"downloads\").find(\"li\").a[\"href\"]\n",
    "    title = (i.find(class_=\"description\").h3.text).replace(\" Enhanced\", \"\")\n",
    "    hemi_dicts.append({\"Title\": title, \"Image Url\":img_url})\n",
    "\n",
    "# Display list of dictionaries\n",
    "hemi_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display images\n",
    "for dict in hemi_dicts:\n",
    "    display(Image(url=dict.get(\"Image Url\", \"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'latest_news': \"NASA's InSight Detects First Likely 'Quake' on Mars\", 'latest_paragraph': 'While their causes are still unknown, one of three shaking events looks a lot like the quakes detected on the Moon by the Apollo missions.', 'featured_image_url': 'https://www.jpl.nasa.gov/spaceimages/images/mediumsize/PIA19347_ip.jpg', 'mars_weather': 'InSight sol 143 (2019-04-22) low -98.0ºC (-144.3ºF) high -19.8ºC (-3.7ºF)\\nwinds from the SW at 4.5 m/s (10.1 mph) gusting to 12.1 m/s (27.2 mph)\\npressure at 7.40 hPapic.twitter.com/EOazNkJqjD', 'mars_table': '<table border=\"1\" class=\"dataframe marsdata\">   <thead>     <tr style=\"text-align: right;\">       <th></th>       <th>Data</th>     </tr>     <tr>       <th>Parameter</th>       <th></th>     </tr>   </thead>   <tbody>     <tr>       <th>Equatorial Diameter:</th>       <td>6,792 km</td>     </tr>     <tr>       <th>Polar Diameter:</th>       <td>6,752 km</td>     </tr>     <tr>       <th>Mass:</th>       <td>6.42 x 10^23 kg (10.7% Earth)</td>     </tr>     <tr>       <th>Moons:</th>       <td>2 (Phobos &amp; Deimos)</td>     </tr>     <tr>       <th>Orbit Distance:</th>       <td>227,943,824 km (1.52 AU)</td>     </tr>     <tr>       <th>Orbit Period:</th>       <td>687 days (1.9 years)</td>     </tr>     <tr>       <th>Surface Temperature:</th>       <td>-153 to 20 °C</td>     </tr>     <tr>       <th>First Record:</th>       <td>2nd millennium BC</td>     </tr>     <tr>       <th>Recorded By:</th>       <td>Egyptian astronomers</td>     </tr>   </tbody> </table>', 'hemi_dicts': [{'Title': 'Cerberus Hemisphere', 'Image Url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg'}, {'Title': 'Schiaparelli Hemisphere', 'Image Url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg'}, {'Title': 'Syrtis Major Hemisphere', 'Image Url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg'}, {'Title': 'Valles Marineris Hemisphere', 'Image Url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg'}]}\n"
     ]
    }
   ],
   "source": [
    "print(scraper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
